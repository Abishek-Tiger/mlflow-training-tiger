{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic example\n",
    "\n",
    "* The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "* P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "* Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tracking experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the MLflow tracking server by \n",
    "\n",
    "```\n",
    "mlflow server \\\n",
    "    --backend-store-uri /mnt/persistent-disk \\\n",
    "    --default-artifact-root s3://my-mlflow-bucket/ \\\n",
    "    --host 0.0.0.0\n",
    "```\n",
    "\n",
    "or use the default storage method to write to `mlruns/`. MLflow supports two types of backend stores: *file store* and *database-backed* store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0\n",
    "remote_server_uri = \"http://0.0.0.0:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or MLFLOW_TRACKING_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking store\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`\n",
    "- Database encoded as <dialect>+<driver>://<username>:<password>@<host>:<port>/<database>. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://<profileName>, a Databricks CLI profile. See docs on logging to Databricks-hosted MLflow, or the quickstart to easily get started with hosted MLflow on Databricks Community Edition.\n",
    "    \n",
    "### Artifact stores\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://0.0.0.0:5000'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid = mlflow.create_experiment(name=\"ElasticNet_wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def train(in_alpha, in_l1_ratio):\n",
    "    # train a model with given parameters\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n",
    "    data_path = \"data/wine-quality.csv\"\n",
    "    train_x, train_y, test_x, test_y = load_data(data_path)\n",
    "\n",
    "    # Set default values if no alpha is provided\n",
    "    if float(in_alpha) is None:\n",
    "        alpha = 0.5\n",
    "    else:\n",
    "        alpha = float(in_alpha)\n",
    "\n",
    "    # Set default values if no l1_ratio is provided\n",
    "    if float(in_l1_ratio) is None:\n",
    "        l1_ratio = 0.5\n",
    "    else:\n",
    "        l1_ratio = float(in_l1_ratio)\n",
    "\n",
    "    # Useful for multiple runs (only doing one run in this sample notebook)    \n",
    "    with mlflow.start_run(experiment_id=eid):\n",
    "        \n",
    "    # could also do\n",
    "    # with mlflow.start_run():\n",
    "    #      for epoch in range(0, 3):\n",
    "    #           mlflow.log_metric(key=\"quality\", value=2*epoch, step=epoch)\n",
    "    \n",
    "        # Execute ElasticNet\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_artifact(data_path)\n",
    "        print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "        \n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 0.82224284975954\n",
      "  MAE: 0.6278761410160693\n",
      "  R2: 0.12678721972772689\n",
      "Save to: mlruns/1/d671f37a9c7f478989e67eb4ff4d1dac/artifacts\n"
     ]
    }
   ],
   "source": [
    "train(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.200000, l1_ratio=0.200000):\n",
      "  RMSE: 0.7859129997062342\n",
      "  MAE: 0.6155290394093895\n",
      "  R2: 0.2022463182289208\n"
     ]
    }
   ],
   "source": [
    "train(0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.100000, l1_ratio=0.100000):\n",
      "  RMSE: 0.7792546522251949\n",
      "  MAE: 0.6112547988118586\n",
      "  R2: 0.2157063843066196\n"
     ]
    }
   ],
   "source": [
    "train(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Comparing runs\n",
    "Run `mlflow ui` in a terminal or `http://your-tracking-server-host:5000` to view the experiment log and visualize and compare different runs and experiments. The logs and the model artifacts are saved in the `mlruns` directory (or where you specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Packaging the experiment as a project as conda env\n",
    "\n",
    "Specify the entrypoint for this project by creating a `MLproject` file and adding an conda environment with a `conda.yaml`. You can copy the yaml file from the experiment logs.\n",
    "\n",
    "To run this project, invoke `mlflow run . -P alpha=0.42`. After running this command, MLflow runs your training code in a new Conda environment with the dependencies specified in `conda.yaml`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy the model\n",
    "\n",
    "Deploy the model locally by running \n",
    "\n",
    "`mlflow models serve -m mlruns/0/f5f7c052ddc5469a852aa52c14cabdf1/artifacts/model/ -h 0.0.0.0 -p 1234`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the endpoint:\n",
    "\n",
    "`curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://0.0.0.0:1234/invocations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources:\n",
    "\n",
    "- MLflow: Infrastructure for a Complete Machine Learning Life Cycle with Mani Parkhe & Tomas Nykod: https://www.youtube.com/watch?v=wb-ZxtIwSTA\n",
    "- https://mlflow.org/docs/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
